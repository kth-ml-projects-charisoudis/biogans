import math
from typing import Optional, Union

import torch
import torch.nn as nn
import torch.utils.data
from torch import Tensor
# noinspection PyProtectedMember
from torch.utils.data import Dataset, DataLoader
from torchvision.transforms import transforms

from utils.ifaces import FilesystemFolder, Freezable
from utils.metrics.fid import FID


class IS(FID):
    """
    IS Class:
    This class is used to compute the Inception Score (IS) between two given image sets.
    """

    def __init__(self, model_fs_folder_or_root: Union[FilesystemFolder, str], device: torch.device or str = 'cpu',
                 n_samples: int = 512, batch_size: int = 8, ):
        """
        IS class constructor.
        :param (FilesystemFolder or str) model_fs_folder_or_root: absolute path to model checkpoints directory or
                                                                  FilesystemFolder instance for cloud-synced models
        :param n_samples: the total number of samples used to compute the metric (defaults to 512; the higher this
                          number gets, the more accurate the metric is)
        :param batch_size: the number of samples to precess at each loop
        :param device: the device type on which to run the Inception model (defaults to 'cpu')
        """
        super(IS, self).__init__(model_fs_folder_or_root=model_fs_folder_or_root, device=device,
                                 n_samples=n_samples, batch_size=batch_size)

    # noinspection DuplicatedCode,PyUnusedLocal
    def forward(self, dataset: Dataset, gen: nn.Module, target_index: Optional[int] = None,
                condition_indices: Optional[Union[int, tuple]] = None, z_dim: Optional[int] = None,
                show_progress: bool = True, **kwargs) -> Tensor:
        """
        Compute the Inception Score of the images generated by the given generator network.
        :param dataset: a torch.utils.data.Dataset object to access real images. Attention: no transforms should be
                        applied when __getitem__ is called since the transforms are different on Inception v3
        :param gen: the Generator network
        :param target_index: NOT used in IS
        :param condition_indices: indices of images that will be passed to the Generator in order to generate fake
                                  images (for image-to-image translation tasks). If set to None, the generator is fed
                                  with random noise.
        :param z_dim: if $condition_indices$ is None, then this is necessary to produce random noise to feed into the
                      DCGAN-like generator
        :param (bool) show_progress: set to True to display progress using `tqdm` lib
        :return: a scalar torch.Tensor containing the computed IS value
        """
        dataloader = DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)

        if self.device == 'cuda:0' and torch.cuda.is_available():
            torch.cuda.empty_cache()

        assert isinstance(gen, Freezable), 'Generator should implement utils.ifaces.Freezable'
        with gen.frozen():
            cur_samples = 0
            fake_predictions_list = []
            break_after = False
            for real_samples in self.tqdm(dataloader, total=int(math.ceil(self.n_samples / self.batch_size)),
                                          disable=not show_progress, desc="IS"):
                if cur_samples >= self.n_samples:
                    break_after = True

                if hasattr(gen, 'resolution'):
                    real_samples = transforms.Resize(size=gen.resolution)(real_samples)

                cur_batch_size = len(real_samples if condition_indices is None else real_samples[0])

                # Compute predictions on fake
                gen_inputs = torch.randn(cur_batch_size, z_dim, device=self.device)
                # gen_inputs = [gen_transforms(gen_input).to(self.device) for gen_input in gen_inputs] \
                #     if condition_indices is not None else gen_inputs.to(self.device)
                fake_output = gen(gen_inputs)
                #   - add 3rd channel
                fake_output = torch.concat((fake_output, torch.zeros(fake_output.shape[0], 1, 48, 80).cuda()), dim=1)
                # ATTENTION: In order to pass generator's output through Inception we must re-normalize tensor stats!
                # Generator output images in the range [-1, 1], since it uses a Tanh() activation layer, whereas
                # Inception v3 receives tensors with its custom normalization. Solutions: 1) Invert normalization in
                # gen_transforms and then pass the image through the Inception transforms | 2) Use the new
                # ToTensorOrPass() transform fake_output = gen_transforms_inv(fake_output)
                fake_predictions = FID.InceptionV3Classifier(FID.InceptionV3Transforms(fake_output))
                fake_predictions_list.append(fake_predictions.detach().cpu())

                cur_samples += cur_batch_size
                if break_after:
                    break

            fake_predictions = torch.cat(fake_predictions_list, dim=0)

            # Compute IS
            # Compute marginal distribution, P(y) = 1/|x|*Î£{P(y|x)}, where x ~ P_g
            p_y = torch.mean(fake_predictions, dim=0)
            # Compute D_kl[p(y|xi)||p(y)] for every generated sample xi
            # (credits to hantian_pang, see https://stackoverflow.com/a/54977657/13634700)
            kls = [(p_y_given_xi * (p_y_given_xi / p_y).log()).sum() for p_y_given_xi in fake_predictions]

        return torch.exp(torch.mean(torch.stack(kls), dim=0))
